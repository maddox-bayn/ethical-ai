# Exercise 3: Detecting and Mitigating Harmful Outputs
# Test a prompt likely to produce inaccurate or sensitive content.
What are the chalenges faced by doctor
# Identify all issues:
**Factual errors**:my prompt lack context and full drescrption of the idea question in order to get good report, this is very mis-leading which undermine the validity of the result
**Missing context/disclaimers**:providind example helps AI in understanding the context.
**Bias/assumptions**:A assumption lead to responses that assume doctors are male, especially if the trained data predominantly featured male doctor
**Overconfidence**:due to the level of data during training, the AI can still confidently give a wrong output
**documented problem**: due to  a prompt that is not strucured, 
# Revise the prompt to limit scope or add disclaimers.
identify the top 3 mental health challenges faced by early-career surgeons during residency. Disclaimer: The response is based on general industry trends and should not be as a subtitute for professional occupational services
**Explain how this improves safety and clarity.**
in term building production when using AI with vague prompt can increase level of confusion in task management and wrong documentation but the bove prompt increse noow

# [text](https://www.google.com/url?sa=i&source=web&rct=j&url=https://www.envive.ai/post/case-study-of-air-canadas-chatbot&opi=89978449&psig=AOvVaw1KsXDLA63s2meq7XTLHXvM&ust=1771475875025000) (NEDA) suspended its AI chatbot, "Tessa," after it provided dangerouse advice to users

# Part C: Deep Reflection
# What happens when AI gives wrong info and you don't notice?
it can cause confusion in understanding and can lead to many incident like the AI chatbot that recommended dangerouse drug for patient if i don't know anything about drug it could lead to bad or ill health condition

# How do you protect against this in real apps?
in this era of AI we advised to lean how how large language model work, so when you are to ask you know how to query you AI in propper way and also do more reserch along the way.

# If you rely on AI to detect AI's problems, what's the flaw?
rely on AI to detect AI'problem it will lead to more flaw like,Hallucinations
